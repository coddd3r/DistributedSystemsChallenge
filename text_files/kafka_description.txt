  "A simplified version of a Kafka-style stream processing system. Servers
  provide a set of append-only logs identified by string *keys*. Each integer
  *offset* in a log has one *message*. Offsets may be sparse: not every offset
  must contain a message.

  A client appends a message to a log by making a `send` RPC request with the
  key and value they want to append; the server responds with the offset it
  assigned for that particular message.

  To read a log, a client issues a `poll` RPC request with a map of keys to the
  offsets it wishes to read beginning at. The server returns a `poll_ok`
  response containing a map of keys to vectors of `[offset, message]` pairs,
  beginning at the requested offset for that key.

  Servers should maintain a *committed offset* for each key. Clients can
  request that this offset be advanced by making a `commit_offsets` RPC
  request, with a map of keys to the highest offsets which that client has
  processed. Clients can also fetch known-committed offsets for a given set of
  keys through a `fetch_committed_offsets` request.

  The checker for this workload detects a number of anomalies.

  If a client observes (e.g.) offset 10 of key `k1`, but *not* offset 5, and we
  know that offset 5 exists, we call that a *lost write*. If we know offset 11
  exists, but it is never observed in a poll, we call that write *unobserved*.
  There is no recency requirement: servers are free to acknowledge a sent
  message, but not return it in any polls for an arbitrarily long time.

  Ideally, we expect client offsets from both sends and polls to be strictly
  monotonically increasing, and to observe every message. If offsets go
  backwards--e.g. if a client observes offset 4 then 2, or 2 then 2--we call
  that *nonomonotonic*. It's an *internal nonmonotonic* error if offsets fail
  to increase in the course of a single transaction, or single poll. It's an
  *external nonmonotonic* error if offsets fail to increase *between* two
  transactions.

  If we skip over an offset that we know exists, we call that a *skip*. Like
  nonmonotonic errors, a skip error can be internal (in a single transaction or
  poll) or external (between two transactions). For example, here is a
  poll-skip anomaly:

  ```edn
  {:key \"56\",
   :delta 3,
   :skipped (7 8),
   :ops [#jepsen.history.Op{:index 3820,
                            :time 4650651388,
                            :type :ok,
                            :process 0,
                            :f :poll,
                            :value [[:poll {\"56\" [[4 5] [5 6]]}]]}
         #jepsen.history.Op{:index 3848,
                            :time 4691738701,
                            :type :ok,
                            :process 0,
                            :f :poll,
                            :value [[:poll {\"56\" [[8 9]]}]]}]}
  ```

  Here a single client (process 0) performed two polls in succession, both of
  which observed key \"56\". The first poll observed offsets 4 and 5 (with
  messages 5 and 6). The second poll observed offset 8, with message 9. The
  client unexpectedly jumped three offsets ahead, skipping messages 7 and 8.

  The Jepsen client performs `:assign` operations, which is analogous to the
  Kafka client's `assign`: it picks a new set of keys and offsets for
  successive `poll` operations. On assign, the client fetches committed offsets
  from the server and begins polling from those positions. Since we expect the
  offset to change on assign, external nonmonotonic and skip errors are not
  tracked across `assign` operations."


Community
Github
Twitter
Support forum
Challenge #5a: Single-Node Kafka-Style Log

In this challenge, you’ll need to implement a replicated log service similar to Kafka. Replicated logs are often used as a message bus or an event stream.

This challenge is broken up in multiple sections so that you can build out your system incrementally. First, we’ll start out with a single-node log system and then we’ll distribute it in later challenges.
Specification

Your nodes will need to store an append-only log in order to handle the "kafka" workload. Each log is identified by a string key (e.g. "k1") and these logs contain a series of messages which are identified by an integer offset. These offsets can be sparse in that not every offset must contain a message.

Maelstrom will check to make sure several anomalies do not occur:

    Lost writes: for example, a client sees offset 10 but not offset 5.
    Monotonic increasing offsets: an offset for a log should always be increasing. 

There are no recency requirements so acknowledged send messages do not need to return in poll messages immediately.
RPC: send

This message requests that a "msg" value be appended to a log identified by "key". Your node will receive a request message body that looks like this:

{
  "type": "send",
  "key": "k1",
  "msg": 123
}

In response, it should send an acknowledge with a send_ok message that contains the unique offset for the message in the log:

{
  "type": "send_ok",
  "offset": 1000
}

RPC: poll

This message requests that a node return messages from a set of logs starting from the given offset in each log. Your node will receive a request message body that looks like this:

{
  "type": "poll",
  "offsets": {
    "k1": 1000,
    "k2": 2000
  }
}

In response, it should return a poll_ok message with messages starting from the given offset for each log. Your server can choose to return as many messages for each log as it chooses:

{
  "type": "poll_ok",
  "msgs": {
    "k1": [[1000, 9], [1001, 5], [1002, 15]],
    "k2": [[2000, 7], [2001, 2]]
  }
}

RPC: commit_offsets

This message informs the node that messages have been successfully processed up to and including the given offset. Your node will receive a request message body that looks like this:

{
  "type": "commit_offsets",
  "offsets": {
    "k1": 1000,
    "k2": 2000
  }
}

In this example, the messages have been processed up to and including offset 1000 for log k1 and all messages up to and including offset 2000 for k2.

In response, your node should return a commit_offsets_ok message body to acknowledge the request:

{
  "type": "commit_offsets_ok"
}

RPC: list_committed_offsets

This message returns a map of committed offsets for a given set of logs. Clients use this to figure out where to start consuming from in a given log.

Your node will receive a request message body that looks like this:

{
  "type": "list_committed_offsets",
  "keys": ["k1", "k2"]
}

In response, your node should return a list_committed_offsets_ok message body containing a map of offsets for each requested key. Keys that do not exist on the node can be omitted.

{
  "type": "list_committed_offsets_ok",
  "offsets": {
    "k1": 1000,
    "k2": 2000
  }
}

Evaluation

Build your Go binary as maelstrom-kafka and run it against Maelstrom with the following command:

./maelstrom test -w kafka --bin ~/go/bin/maelstrom-kafka --node-count 1 --concurrency 2n --time-limit 20 --rate 1000

This will run a single node for 20 seconds with two clients. It will validate that messages are queued and committed properly.

If you’re successful, wahoo! Continue on to the Multi-Node Kafka challenge. If you’re having trouble, jump over to the Fly.io Community forum for help.

Echo

Get the hang of working with Maelstrom in Go by creating a node which is a binary that receives JSON messages
Read More About Echo
Unique ID Generation

Implement a globally-unique ID generation system that runs against Maelstrom's unique-ids workload
Read More About Unique ID Generation
Broadcast

Implement a broadcast system that gossips messages between all nodes in the cluster. Gossiping is a common way
Read More About Broadcast
Grow-Only Counter

Implement a stateless, grow-only counter which will run against Maelstrom's g-counter workload. This
Read More About Grow-Only Counter
5
Kafka-Style Log

Implement a replicated log service similar to Kafka. Replicated logs are often used as a message bus or
Read More About Kafka-Style Log
6
Totally-Available Transactions

Implement a key/value store which implements transactions. These transactions contain micro-operations

    Read More About Totally-Available Transactions

